{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#ignore warning messages \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:\\Users\\singh\\OneDrive\\Desktop\\HANDWRITING RECOGNIZER\\A_Z Handwritten Data.csv\").astype('float32')\n",
    "dataset.rename(columns={'0':'label'}, inplace=True)\n",
    "\n",
    "# Splite data the X - Our data , and y - the prdict label\n",
    "X = dataset.drop('label',axis = 1)\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape:\",X.shape)\n",
    "print(\"culoms count:\",len(X.iloc[1]))\n",
    "print(\"784 = 28X28\")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_shuffle = shuffle(X)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "row, colums = 4, 4\n",
    "for i in range(16):  \n",
    "    plt.subplot(colums, row, i+1)\n",
    "    plt.imshow(X_shuffle.iloc[i].values.reshape(28,28),interpolation='nearest', cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amount of each labels\")\n",
    "\n",
    "# Change label to alphabets\n",
    "alphabets_mapper = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'} \n",
    "dataset_alphabets = dataset.copy()\n",
    "dataset['label'] = dataset['label'].map(alphabets_mapper)\n",
    "\n",
    "label_size = dataset.groupby('label').size()\n",
    "label_size.plot.barh(figsize=(10,10))\n",
    "plt.show()\n",
    "\n",
    "print(\"We have very low observations for I and F \")\n",
    "print(\"I count:\", label_size['I'])\n",
    "print(\"F count:\", label_size['F'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splite the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# scale data\n",
    "standard_scaler = MinMaxScaler()\n",
    "standard_scaler.fit(X_train)\n",
    "\n",
    "X_train = standard_scaler.transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data after scaler\")\n",
    "X_shuffle = shuffle(X_train)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "row, colums = 4, 4\n",
    "for i in range(16):  \n",
    "    plt.subplot(colums, row, i+1)\n",
    "    plt.imshow(X_shuffle[i].reshape(28,28),interpolation='nearest', cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = Sequential()\n",
    "cls.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "cls.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cls.add(Dropout(0.3))\n",
    "cls.add(Flatten())\n",
    "cls.add(Dense(128, activation='relu'))\n",
    "cls.add(Dense(len(y.unique()), activation='softmax'))\n",
    "\n",
    "cls.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = cls.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=18, batch_size=200, verbose=2)\n",
    "\n",
    "scores = cls.evaluate(X_test,y_test, verbose=0)\n",
    "print(\"CNN Score:\",scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test.argmax(axis=1),cls.predict(X_test).argmax(axis=1))\n",
    "df_cm = pd.DataFrame(cm, range(26),\n",
    "                  range(26))\n",
    "plt.figure(figsize = (20,15))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U coremltools\n",
    "import coremltools\n",
    "\n",
    "cls.save('best.h5')\n",
    "\n",
    "output_labels = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "core_ml=coremltools.converters.keras.convert('besth5', input_names=['image'], output_names=['output'], \n",
    "    class_labels=output_labels,image_scale=1/255.0, is_bgr = False, image_input_names = \"image\")\n",
    "core_ml.save('coreml_model.mlmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
